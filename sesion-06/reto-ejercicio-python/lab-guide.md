# [Reto] Ejercicio Python para Machine Learning

## Informaci√≥n general del laboratorio

Este es un laboratorio de desaf√≠o dise√±ado para evaluar y fortalecer sus habilidades en Python aplicadas a Machine Learning. En lugar de seguir instrucciones paso a paso, se le presentar√°n problemas reales que debe resolver usando Python, pandas, numpy y scikit-learn en un entorno de AWS.

El reto consiste en analizar un conjunto de datos de ventas de una empresa, realizar an√°lisis exploratorio de datos (EDA), crear modelos predictivos y generar insights accionables para el negocio.

## Objetivos del reto

Al completar este reto, habr√° demostrado su capacidad para:

- Manipular y limpiar datos usando pandas
- Realizar an√°lisis exploratorio de datos (EDA)
- Crear visualizaciones informativas
- Implementar modelos de Machine Learning
- Evaluar y optimizar modelos
- Generar insights de negocio basados en datos
- Trabajar con APIs y servicios web
- Manejar datos en tiempo real

## Duraci√≥n

El tiempo estimado para completar este reto es de **40 minutos**.

## Configuraci√≥n del entorno

### Tarea 1: Conectarse a la instancia EC2

1. En la **Consola de administraci√≥n de AWS**, navegue a **EC2**.

2. Seleccione la instancia llamada **Python ML Lab Instance**.

3. Con√©ctese usando **EC2 Instance Connect** o SSH.

4. Una vez conectado, verifique las herramientas instaladas:
   ```bash
   python3 --version
   pip3 list | grep -E "(pandas|numpy|scikit-learn|matplotlib|seaborn)"
   ```

## Escenario del reto

Usted es un Data Scientist en "TechRetail Corp", una empresa de comercio electr√≥nico. El equipo de negocio necesita insights sobre el comportamiento de compra de los clientes para optimizar las estrategias de marketing y ventas.

Se le han proporcionado datos hist√≥ricos de transacciones y debe:

1. **Limpiar y preparar** los datos para an√°lisis
2. **Realizar EDA** para entender patrones de compra
3. **Crear modelos predictivos** para segmentaci√≥n de clientes
4. **Predecir el valor de vida del cliente** (Customer Lifetime Value)
5. **Generar recomendaciones** basadas en an√°lisis

## Datos disponibles

### Dataset principal: `sales_data.csv`

```csv
customer_id,transaction_date,product_category,product_name,quantity,unit_price,total_amount,customer_age,customer_gender,customer_location,marketing_channel
CUST001,2024-01-15,Electronics,Smartphone,1,699.99,699.99,28,M,New York,Online
CUST002,2024-01-15,Clothing,T-Shirt,3,25.99,77.97,34,F,California,Email
CUST003,2024-01-16,Electronics,Laptop,1,1299.99,1299.99,42,M,Texas,Social Media
```

### Dataset complementario: `customer_support.csv`

```csv
customer_id,support_tickets,avg_resolution_time,satisfaction_score,last_contact_date
CUST001,2,24,4.5,2024-01-10
CUST002,0,0,5.0,2024-01-01
CUST003,1,12,4.8,2024-01-12
```

## Retos a resolver

### Reto 1: An√°lisis Exploratorio de Datos (EDA)
**Tiempo estimado: 15 minutos**

Cree un notebook Jupyter o script Python que responda:

1. **An√°lisis b√°sico**:
   - ¬øCu√°ntas transacciones √∫nicas hay en el dataset?
   - ¬øCu√°l es el rango de fechas de los datos?
   - ¬øCu√°ntos clientes √∫nicos tenemos?

2. **An√°lisis de ventas**:
   - ¬øCu√°les son los top 5 productos m√°s vendidos?
   - ¬øQu√© categor√≠a genera m√°s ingresos?
   - ¬øCu√°l es la distribuci√≥n de montos de transacci√≥n?

3. **An√°lisis de clientes**:
   - ¬øCu√°l es la distribuci√≥n por edad y g√©nero?
   - ¬øQu√© canal de marketing es m√°s efectivo?
   - ¬øCu√°l es el ticket promedio por cliente?

**C√≥digo de inicio**:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de gr√°ficos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Cargar datos
def load_data():
    """
    Cargar y preparar los datasets
    """
    # TODO: Implementar carga de datos
    # Puede simular datos si no tiene acceso a archivos reales
    pass

def basic_eda(df):
    """
    Realizar an√°lisis exploratorio b√°sico
    """
    print("=== AN√ÅLISIS EXPLORATORIO DE DATOS ===\n")
    
    # TODO: Implementar an√°lisis b√°sico
    # - Informaci√≥n general del dataset
    # - Estad√≠sticas descriptivas
    # - Valores faltantes
    # - Distribuciones principales
    
    pass

# Ejecutar an√°lisis
df_sales = load_data()
basic_eda(df_sales)
```

### Reto 2: Segmentaci√≥n de Clientes con RFM
**Tiempo estimado: 15 minutos**

Implemente un an√°lisis RFM (Recency, Frequency, Monetary) para segmentar clientes:

1. **Calcule m√©tricas RFM**:
   - **Recency**: D√≠as desde la √∫ltima compra
   - **Frequency**: N√∫mero total de transacciones
   - **Monetary**: Valor total de compras

2. **Cree segmentos de clientes**:
   - Champions (R: 4-5, F: 4-5, M: 4-5)
   - Loyal Customers (R: 2-5, F: 3-5, M: 3-5)
   - Potential Loyalists (R: 3-5, F: 1-3, M: 1-3)
   - At Risk (R: 1-2, F: 2-5, M: 2-5)
   - Lost Customers (R: 1-2, F: 1-2, M: 1-2)

3. **Analice los segmentos**:
   - Tama√±o de cada segmento
   - Valor promedio por segmento
   - Caracter√≠sticas demogr√°ficas

**C√≥digo de inicio**:

```python
def calculate_rfm(df):
    """
    Calcular m√©tricas RFM para cada cliente
    """
    # Fecha de referencia (√∫ltima fecha en los datos + 1 d√≠a)
    reference_date = df['transaction_date'].max() + timedelta(days=1)
    
    rfm = df.groupby('customer_id').agg({
        'transaction_date': lambda x: (reference_date - x.max()).days,  # Recency
        'customer_id': 'count',  # Frequency
        'total_amount': 'sum'    # Monetary
    }).reset_index()
    
    rfm.columns = ['customer_id', 'recency', 'frequency', 'monetary']
    
    # TODO: Implementar scoring RFM (1-5 para cada m√©trica)
    # TODO: Crear segmentos basados en scores RFM
    
    return rfm

def create_customer_segments(rfm_df):
    """
    Crear segmentos de clientes basados en RFM
    """
    # TODO: Implementar l√≥gica de segmentaci√≥n
    # TODO: Asignar nombres de segmentos
    # TODO: Calcular estad√≠sticas por segmento
    
    pass

# Ejecutar segmentaci√≥n RFM
rfm_analysis = calculate_rfm(df_sales)
segments = create_customer_segments(rfm_analysis)
```

### Reto 3: Modelo Predictivo de Customer Lifetime Value
**Tiempo estimado: 10 minutos**

Cree un modelo para predecir el CLV (Customer Lifetime Value):

1. **Prepare las caracter√≠sticas**:
   - M√©tricas RFM
   - Datos demogr√°ficos
   - Historial de soporte
   - Canal de adquisici√≥n

2. **Entrene un modelo**:
   - Use Random Forest o Gradient Boosting
   - Divida en train/test (80/20)
   - Eval√∫e con MAE, RMSE y R¬≤

3. **Genere predicciones**:
   - CLV para pr√≥ximos 12 meses
   - Identifique clientes de alto valor
   - Ranking de clientes por CLV predicho

**C√≥digo de inicio**:

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder, StandardScaler

def prepare_features_for_clv(df_sales, df_support):
    """
    Preparar caracter√≠sticas para modelo CLV
    """
    # TODO: Crear caracter√≠sticas agregadas por cliente
    # TODO: Combinar con datos de soporte
    # TODO: Codificar variables categ√≥ricas
    # TODO: Manejar valores faltantes
    
    pass

def train_clv_model(features_df, target_col='clv_12_months'):
    """
    Entrenar modelo de predicci√≥n CLV
    """
    # Separar caracter√≠sticas y target
    X = features_df.drop([target_col, 'customer_id'], axis=1)
    y = features_df[target_col]
    
    # Divisi√≥n train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # TODO: Entrenar modelo
    # TODO: Evaluar rendimiento
    # TODO: Analizar importancia de caracter√≠sticas
    
    return model, X_test, y_test

# Ejecutar modelado CLV
features = prepare_features_for_clv(df_sales, df_support)
clv_model, X_test, y_test = train_clv_model(features)
```

## Retos adicionales (Opcionales)

### Reto 4: Detecci√≥n de Anomal√≠as

Implemente un sistema para detectar transacciones an√≥malas:

```python
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

def detect_anomalies(df):
    """
    Detectar transacciones an√≥malas
    """
    # TODO: Preparar caracter√≠sticas num√©ricas
    # TODO: Usar Isolation Forest
    # TODO: Identificar patrones en anomal√≠as
    
    pass
```

### Reto 5: Sistema de Recomendaciones

Cree un sistema b√°sico de recomendaci√≥n de productos:

```python
from sklearn.metrics.pairwise import cosine_similarity

def create_product_recommendations(df):
    """
    Sistema de recomendaciones basado en colaborative filtering
    """
    # TODO: Crear matriz customer-product
    # TODO: Calcular similitudes
    # TODO: Generar recomendaciones
    
    pass
```

### Reto 6: API de Predicciones

Cree una API simple usando Flask para servir predicciones:

```python
from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)

# Cargar modelo entrenado
model = joblib.load('clv_model.pkl')

@app.route('/predict_clv', methods=['POST'])
def predict_clv():
    """
    API endpoint para predicci√≥n CLV
    """
    # TODO: Procesar request JSON
    # TODO: Hacer predicci√≥n
    # TODO: Retornar resultado
    
    pass

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
```

## Criterios de evaluaci√≥n

Su soluci√≥n ser√° evaluada en base a:

### Calidad del c√≥digo (30%)
- ‚úÖ C√≥digo limpio y bien documentado
- ‚úÖ Uso apropiado de librer√≠as de Python
- ‚úÖ Manejo adecuado de errores
- ‚úÖ Estructura l√≥gica y modular

### An√°lisis de datos (25%)
- ‚úÖ EDA completo y revelador
- ‚úÖ Visualizaciones claras e informativas
- ‚úÖ Interpretaci√≥n correcta de resultados
- ‚úÖ Identificaci√≥n de patrones relevantes

### Modelado (25%)
- ‚úÖ Preparaci√≥n adecuada de datos
- ‚úÖ Selecci√≥n apropiada de algoritmos
- ‚úÖ Evaluaci√≥n rigurosa de modelos
- ‚úÖ Interpretaci√≥n de resultados

### Insights de negocio (20%)
- ‚úÖ Recomendaciones accionables
- ‚úÖ Comunicaci√≥n clara de hallazgos
- ‚úÖ Conexi√≥n entre an√°lisis y valor de negocio
- ‚úÖ Consideraci√≥n de limitaciones y pr√≥ximos pasos

## Datos sint√©ticos para pruebas

Si no tiene acceso a datos reales, use este c√≥digo para generar datos sint√©ticos:

```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

def generate_synthetic_data(n_customers=1000, n_transactions=5000):
    """
    Generar datos sint√©ticos para el reto
    """
    np.random.seed(42)
    
    # Generar clientes
    customers = []
    for i in range(n_customers):
        customers.append({
            'customer_id': f'CUST{i:04d}',
            'customer_age': np.random.randint(18, 70),
            'customer_gender': np.random.choice(['M', 'F']),
            'customer_location': np.random.choice(['New York', 'California', 'Texas', 'Florida', 'Illinois']),
            'marketing_channel': np.random.choice(['Online', 'Email', 'Social Media', 'Referral', 'Direct'])
        })
    
    # Generar transacciones
    products = [
        ('Electronics', 'Smartphone', 699.99),
        ('Electronics', 'Laptop', 1299.99),
        ('Electronics', 'Tablet', 399.99),
        ('Clothing', 'T-Shirt', 25.99),
        ('Clothing', 'Jeans', 79.99),
        ('Home', 'Coffee Maker', 149.99),
        ('Books', 'Python Guide', 39.99),
        ('Sports', 'Running Shoes', 129.99)
    ]
    
    transactions = []
    start_date = datetime(2023, 1, 1)
    end_date = datetime(2024, 1, 31)
    
    for _ in range(n_transactions):
        customer = np.random.choice(customers)
        category, product, base_price = np.random.choice(products)
        quantity = np.random.randint(1, 5)
        unit_price = base_price * np.random.uniform(0.8, 1.2)  # Variaci√≥n de precio
        
        transactions.append({
            'customer_id': customer['customer_id'],
            'transaction_date': start_date + timedelta(
                days=np.random.randint(0, (end_date - start_date).days)
            ),
            'product_category': category,
            'product_name': product,
            'quantity': quantity,
            'unit_price': round(unit_price, 2),
            'total_amount': round(quantity * unit_price, 2),
            'customer_age': customer['customer_age'],
            'customer_gender': customer['customer_gender'],
            'customer_location': customer['customer_location'],
            'marketing_channel': customer['marketing_channel']
        })
    
    return pd.DataFrame(transactions)

# Generar datos sint√©ticos
df_sales = generate_synthetic_data()
print(f"Dataset generado: {len(df_sales)} transacciones")
print(df_sales.head())
```

## Entrega del reto

Para completar el reto, debe entregar:

1. **Notebook Jupyter** o scripts Python con todo el an√°lisis
2. **Visualizaciones** claras y profesionales
3. **Modelos entrenados** guardados con joblib/pickle
4. **Reporte ejecutivo** (1-2 p√°ginas) con insights clave
5. **C√≥digo de API** (si implement√≥ el reto adicional)

## Consejos para el √©xito

- üìä **Visualice todo**: Los gr√°ficos comunican mejor que las tablas
- üßπ **Limpie los datos**: Dedique tiempo a entender y limpiar los datos
- üéØ **Enf√≥quese en el negocio**: Conecte cada an√°lisis con valor comercial
- ‚ö° **Itere r√°pidamente**: Haga an√°lisis b√°sico primero, refine despu√©s
- üìù **Documente todo**: Explique su razonamiento y decisiones
- üß™ **Valide resultados**: Use m√∫ltiples m√©tricas y t√©cnicas de validaci√≥n

## Recursos de apoyo

- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)
- [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)

---

**¬°Buena suerte con el reto!** üêçüöÄ

Este ejercicio le permitir√° demostrar sus habilidades en Python y Machine Learning aplicadas a problemas reales de negocio.
